import typing as tp
import time

import numpy as np
import pandas as pd
from pymilvus import (
    AsyncMilvusClient,
    CollectionSchema,
    DataType,
    FieldSchema,
)
from sentence_transformers import SentenceTransformer

from app.common.exceptions.exceptions import (
    NotFoundError,
)
from app.common.logger import AISearchLogger
from app.infrastructure.storages.interfaces import IVectorDatabase
from app.infrastructure.utils.nlp import l2_normalize
from app.infrastructure.utils.metrics import metrics_print
from app.settings.config import MilvusSettings


class MilvusDatabase(IVectorDatabase):
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Milvus DB —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AsyncMilvusClient."""

    def __init__(self, settings: MilvusSettings, logger: AISearchLogger):
        milvus_init_start = time.perf_counter()
        self.config = settings
        self.logger = logger
        self.client = AsyncMilvusClient(
            uri=f"http{'s' if self.config.use_ssl else ''}://{self.config.host}:{self.config.port}",
            timeout=self.config.connection_timeout,
        )
        self.__collections_loaded = set()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        self.initialize_model_metadata_collection()
        self.preload_collections()
        metrics_print("üïí –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Milvus", milvus_init_start)


    @staticmethod
    def get_model_name(model: SentenceTransformer) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è –º–æ–¥–µ–ª–∏"""
        return model._first_module().auto_model.config._name_or_path.split("/")[-1]

    async def create_collection(
        self,
        collection_name: str,
        dim: int,
        metadata_fields: list[str],
        metadata_maxlen: int = 65535,
    ) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
        collections = await self.client.list_collections(timeout=self.config.query_timeout)
        if collection_name in collections:
            await self.client.drop_collection(collection_name, timeout=self.config.query_timeout)

        # –°–æ–∑–¥–∞–µ–º —Å—Ö–µ–º—É –ø–æ–ª–µ–π
        fields = [
            FieldSchema(
                name=self.config.id_field, dtype=DataType.INT64, is_primary=True, auto_id=True
            ),
            FieldSchema(name=self.config.vector_field, dtype=DataType.FLOAT_VECTOR, dim=dim),
            *[
                FieldSchema(name=field, dtype=DataType.VARCHAR, max_length=metadata_maxlen)
                for field in metadata_fields
            ],
        ]

        schema = CollectionSchema(fields, description=f"Collection {collection_name}")

        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        await self.client.create_collection(
            collection_name=collection_name, schema=schema, timeout=self.config.query_timeout
        )

        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–¥–µ–∫—Å–∞
        index_params = self.client.prepare_index_params()
        index_params.add_index(
            field_name=self.config.vector_field,
            index_type="HNSW",
            metric_type=self.config.metric_type,
            params={"M": 16, "efConstruction": 128},
        )

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
        await self.client.create_index(
            collection_name=collection_name,
            index_params=index_params,
            timeout=self.config.query_timeout,
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        await self.client.load_collection(collection_name, timeout=self.config.query_timeout)
        self.__collections_loaded.add(collection_name)

    async def insert_vectors(
        self,
        collection_name: str,
        vectors: list[list[float]],  # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
        metadata: pd.DataFrame | None = None,
        batch_size: int = 512,
    ) -> None:
        """–í—Å—Ç–∞–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é."""
        vectors_size = len(vectors)

        if metadata is not None:
            data_size = len(metadata.index)
            if vectors_size != data_size:
                raise ValueError(
                    f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫ –≤ DataFrame ({vectors_size} != {data_size})"
                )

            rows = []
            for _, r in metadata.iterrows():
                row_dict = {col: str(r[col]) for col in metadata.columns}
                rows.append(row_dict)
        else:
            rows = [{} for _ in range(vectors_size)]
            if vectors_size == 0:
                raise ValueError("–ù–µ–ª—å–∑—è –≤—Å—Ç–∞–≤–∏—Ç—å 0 –≤–µ–∫—Ç–æ—Ä–æ–≤ –±–µ–∑ DataFrame")

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if collection_name not in self.__collections_loaded:
            await self.client.load_collection(collection_name, timeout=self.config.query_timeout)
            self.__collections_loaded.add(collection_name)

        num_batches = (vectors_size + batch_size - 1) // batch_size
        self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤{' –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö' if metadata is not None else ''} ...")

        for i in range(num_batches):
            start = i * batch_size
            end = min(start + batch_size, vectors_size)
            vectors_batch = vectors[start:end]
            rows_batch = rows[start:end]

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
            data = []
            for vector, row in zip(vectors_batch, rows_batch):
                item = {self.config.vector_field: vector, **row}
                data.append(item)

            # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            await self.client.insert(
                collection_name=collection_name, data=data, timeout=self.config.query_timeout
            )
            self.logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {i+1}/{num_batches} ...")

        # –í—ã–ø–æ–ª–Ω—è–µ–º flush –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –∑–∞–ø–∏—Å–∏
        await self.client.flush(collection_name, timeout=self.config.query_timeout)

    async def search(
        self, collection_name: str, query_vector: list[float], top_k: int
    ) -> list[dict[str, tp.Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏."""
        top_k = max(top_k, 1)

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if collection_name not in self.__collections_loaded:
            await self.client.load_collection(collection_name, timeout=self.config.query_timeout)
            self.__collections_loaded.add(collection_name)

        results = await self.client.search(
            collection_name=collection_name,
            data=[query_vector],
            anns_field=self.config.vector_field,
            params={"metric_type": self.config.metric_type, "params": {"ef": 64}},
            limit=top_k,
            output_fields=self.config.output_fields,
            timeout=self.config.query_timeout,
        )

        out: list[dict[str, tp.Any]] = []
        if not results:
            return out
        hits = results[0]
        for h in hits:
            fields = h.entity
            row = {k: fields.get(k, "") for k in self.config.output_fields}
            row["score_dense"] = float(h.distance)
            out.append(row)
        return out

        # return [{"id": hit["id"], "distance": hit["distance"]} for hits in results for hit in hits]

    async def collection_ready(self, collection_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏."""
        try:
            collections = await self.client.list_collections(timeout=self.config.query_timeout)
            if collection_name not in collections:
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω–¥–µ–∫—Å
            indexes = await self.client.list_indexes(collection_name)
            return len(indexes) > 0

        except Exception:
            return False

    async def delete_collection(self, collection_name: str) -> None:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏."""
        self.logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name} ...")

        collections = await self.client.list_collections(timeout=self.config.query_timeout)
        if collection_name not in collections:
            self.logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            self.__collections_loaded.discard(collection_name)
            return

        await self.client.drop_collection(collection_name, timeout=self.config.query_timeout)
        self.__collections_loaded.discard(collection_name)
        self.logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞")

    async def get_model_by_collection(self, collection_name: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        try:
            results = await self.client.query(
                collection_name="model_metadata",
                filter=f"collection_name == '{collection_name}'",
                output_fields=["model_name"],
                timeout=self.config.query_timeout,
            )

            if results:
                return results[0]["model_name"]
            else:
                raise NotFoundError(f"–ú–æ–¥–µ–ª—å –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except Exception as e:
            raise NotFoundError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")

    async def update_model_metadata(self, collection_name: str, model_name: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ."""
        self.logger.info(
            f"–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è -> –∏–º—è –º–æ–¥–µ–ª–∏ ({collection_name} -> {model_name}) ..."
        )

        data = [
            {
                "collection_name": collection_name,
                "model_name": model_name,
                "dummy_vector": [0.0, 0.0],  # –≤–µ–∫—Ç–æ—Ä-–∑–∞–≥–ª—É—à–∫–∞
            }
        ]

        await self.client.upsert(
            collection_name="model_metadata", data=data, timeout=self.config.query_timeout
        )
        await self.client.flush("model_metadata", timeout=self.config.query_timeout)

    async def initialize_model_metadata_collection(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏."""
        collections = await self.client.list_collections(timeout=self.config.query_timeout)

        if "model_metadata" not in collections:
            fields = [
                FieldSchema(
                    name="collection_name", dtype=DataType.VARCHAR, max_length=255, is_primary=True
                ),
                FieldSchema(name="model_name", dtype=DataType.VARCHAR, max_length=255),
                FieldSchema(name="dummy_vector", dtype=DataType.FLOAT_VECTOR, dim=2),
            ]

            schema = CollectionSchema(fields, description="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–µ–π")

            await self.client.create_collection(
                collection_name="model_metadata", schema=schema, timeout=self.config.query_timeout
            )

            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è model_metadata
            index_params = self.client.prepare_index_params()
            index_params.add_index(
                field_name="dummy_vector",
                index_type="IVF_FLAT",
                metric_type="L2",
                params={"nlist": 1},
            )

            await self.client.create_index(
                collection_name="model_metadata",
                index_params=index_params,
                timeout=self.config.query_timeout,
            )

            self.logger.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è 'model_metadata' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        await self.client.load_collection("model_metadata", timeout=self.config.query_timeout)
        self.__collections_loaded.add("model_metadata")

    async def preload_collections(self) -> None:
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π –≤ –ø–∞–º—è—Ç—å"""
        for collection_name in self.config.preloaded_collection_names:
            try:
                self.logger.info(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name} ...")
                await self.client.load_collection(
                    collection_name, timeout=self.config.query_timeout
                )
                self.__collections_loaded.add(collection_name)
                self.logger.info(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name}: {e}")

    async def get_model_metadata(self, limit: int = 10) -> list[dict[str, tp.Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ model_metadata"""
        try:
            results = await self.client.query(
                collection_name="model_metadata",
                filter="",
                limit=limit,
                output_fields=["model_name", "collection_name"],
                timeout=self.config.query_timeout,
            )
            return results
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {e}")
            return []

    async def index_documents(
        self,
        collection_name: str,
        model: SentenceTransformer,
        documents: list[str],
        metadata: pd.DataFrame | None = None,
    ) -> None:
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ vector_db."""
        self.logger.info("–ü–†–û–ò–°–•–û–î–ò–¢ –ò–ù–î–ï–ö–°–ê–¶–ò–Ø")
        embeddings = model.encode(documents, normalize_embeddings=True)
        embeddings = np.vstack([l2_normalize(e) for e in embeddings])

        metadata_fields = metadata.columns.tolist() if metadata is not None else []
        await self.create_collection(
            collection_name,
            dim=embeddings.shape[1],
            metadata_fields=metadata_fields,
        )

        await self.insert_vectors(
            collection_name=collection_name, vectors=embeddings.tolist(), metadata=metadata
        )

    async def ensure_collection(
            self,
            collection_name: str,
            model: SentenceTransformer,
            documents: list[str] | None = None,
            metadata: pd.DataFrame | None = None,
            recreate: bool = False,
    ) -> None:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏.

        –ü–æ–≤–µ–¥–µ–Ω–∏–µ:
        - recreate=True ‚Üí –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        - –µ—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Üí —Å–æ–∑–¥–∞—ë—Ç—Å—è –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç—Å—è
        - –µ—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –µ—Å—Ç—å ‚Üí –ø—Ä–æ—Å—Ç–æ load_collection
        - –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ‚Üí –ª–æ–≥–∏—Ä—É–µ–º warning, –Ω–æ –ù–ï –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º
        """

        if recreate:
            self.logger.info(f"‚è≥ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name} (recreate=True) ...")
            if await self.collection_ready(collection_name):
                await self.delete_collection(collection_name=collection_name)
            if documents is None:
                raise ValueError("–î–ª—è recreate=True –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å documents")
            await self.initialize_collection(
                collection_name=collection_name, model=model, documents=documents, metadata=metadata
            )
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
        if not await self.collection_ready(collection_name):
            self.logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞—ë–º ...")
            if documents is None:
                raise ValueError("–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω—É–∂–Ω—ã documents")
            await self.initialize_collection(
                collection_name=collection_name, model=model, documents=documents, metadata=metadata
            )
            return

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Üí –ø—Ä–æ—Å—Ç–æ load_collection
        if collection_name not in self.__collections_loaded:
            await self.client.load_collection(collection_name, timeout=self.config.query_timeout)
            self.__collections_loaded.add(collection_name)
            self.logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –ø–æ–¥–≥—Ä—É–∂–µ–Ω–∞ –≤ –ø–∞–º—è—Ç—å")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ (–Ω–æ –±–µ–∑ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è!)
        try:
            current_model_name = await self.get_model_by_collection(collection_name)
            expected_model_name = MilvusDatabase.get_model_name(model)
            if current_model_name != expected_model_name:
                self.logger.warning(
                    f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å–æ–∑–¥–∞–Ω–∞ —Å –º–æ–¥–µ–ª—å—é {current_model_name}, "
                    f"–∞ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å {expected_model_name}. "
                    f"–ü–æ–∏—Å–∫ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã."
                )
        except NotFoundError:
            self.logger.warning(
                f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö. "
                f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤—Ä—É—á–Ω—É—é."
            )

        # –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –æ–Ω–∞
        expected_model_name = MilvusDatabase.get_model_name(model)
        if current_model_name != expected_model_name:
            self.logger.info(
                f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–∏–ª–∞—Å—å: {current_model_name} -> {expected_model_name}. –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é."
            )
            await self.delete_collection(collection_name=collection_name)
            await self.initialize_collection(
                collection_name=collection_name, model=model, documents=documents, metadata=metadata
            )

    async def initialize_collection(
        self,
        collection_name: str,
        model: SentenceTransformer,
        documents: list[str],
        metadata: pd.DataFrame | None = None,
    ) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª—å—é."""
        self.logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name} ...")
        await self.index_documents(
            collection_name=collection_name, model=model, documents=documents, metadata=metadata
        )
        await self.update_model_metadata(collection_name, MilvusDatabase.get_model_name(model))

    async def close(self) -> None:
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º."""
        if hasattr(self, "client"):
            await self.client.close()
