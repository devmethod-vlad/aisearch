from __future__ import annotations

import asyncio
import contextlib
import json
import threading
import typing as tp
from asyncio import Future
from typing import TYPE_CHECKING

from celery import Celery
from celery.signals import (
    task_prerun,
    worker_process_init,
    worker_process_shutdown,
)

if TYPE_CHECKING:
    from dishka import AsyncContainer

from dishka import AsyncContainer, make_async_container

from app.common.logger import AISearchLogger, LoggerType
from app.common.storages.interfaces import KeyValueStorageProtocol
from app.infrastructure.adapters.interfaces import ILLMQueue, IVLLMAdapter
from app.infrastructure.utils.nlp import download_nltk_resources
from app.settings.config import HybridSearchSettings, Settings, settings

container: AsyncContainer | None = None
model: tp.Any | None = None
drain_task: asyncio.Task | None = None
logger: AISearchLogger | None = None
sweep_task: asyncio.Task | None = None


worker = Celery(
    "aisearch",
    broker=str(settings.redis.dsn),
    backend=str(settings.redis.dsn),
    include=["app.infrastructure.worker.tasks"],
)

worker.conf.update(
    task_serializer="json",
    result_serializer="json",
    accept_content=["json"],
    timezone="UTC",
    task_queues={"default": {"exchange": "default", "routing_key": "default"}},
    task_routes={"search_task": {"queue": "default"}, "generate_task": {"queue": "default"}},
    result_expires=600,
)

worker.autodiscover_tasks(["app.infrastructure.worker.tasks"])

# --- Ð•Ð´Ð¸Ð½Ñ‹Ð¹ event loop ---
loop = asyncio.new_event_loop()


@worker.on_after_configure.connect
def on_after_configure(**kwargs: dict[str, tp.Any]) -> None:
    """ÐšÐ¾Ð´, Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÑŽÑ‰Ð¸Ð¹ÑÑ Ð¿Ð¾ÑÐ»Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Celery Ð¸ ÐµÐ³Ð¾ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº"""
    global logger  # noqa: PLW0603
    logger = AISearchLogger(logger_type=LoggerType.CELERY)
    download_nltk_resources()


def init_container_and_model() -> AsyncContainer:
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð° Dishka"""
    global container, model  # noqa: PLW0603
    from app.infrastructure.ioc import ApplicationProvider
    from app.infrastructure.providers import (
        LoggerProvider,
        MilvusProvider,
        RedisProvider,
    )
    from app.settings.config import (
        AppSettings,
        LLMGlobalSemaphoreSettings,
        LLMQueueSettings,
        MilvusSettings,
        RedisSettings,
        VLLMSettings,
    )

    container = make_async_container(
        ApplicationProvider(),
        LoggerProvider(),
        MilvusProvider(),
        RedisProvider(),
        context={
            AppSettings: settings.app,
            Settings: settings,
            MilvusSettings: settings.milvus,
            RedisSettings: settings.redis,
            LoggerType: LoggerType.CELERY,
            HybridSearchSettings: settings.hybrid,
            LLMGlobalSemaphoreSettings: settings.llm_global_sem,
            LLMQueueSettings: settings.llm_queue,
            VLLMSettings: settings.vllm,
        },
    )

    logger.info(f"Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ {settings.milvus.model_name.split('/')[-1]} ...")
    from sentence_transformers import SentenceTransformer

    model = SentenceTransformer(settings.milvus.model_name)
    logger.info("ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
    return container


def run_coroutine(coro: tp.Coroutine) -> Future:
    """Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ¾Ñ€ÑƒÑ‚Ð¸Ð½ Ð² Ð¾Ð±Ñ‰ÐµÐ¼ event loop."""
    return asyncio.run_coroutine_threadsafe(coro, loop).result()


async def _queue_drain_loop() -> None:
    """Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ ÐºÐ¾Ñ€ÑƒÑ‚Ð¸Ð½Ð°: Ð¶Ð´Ñ‘Ñ‚ Ñ‚Ð¸ÐºÐµÑ‚Ñ‹ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‰Ðµ Ð¸ ÑÑ‚Ð°Ñ€Ñ‚ÑƒÐµÑ‚ celery-Ð·Ð°Ð´Ð°Ñ‡Ð¸."""
    assert container is not None
    queue = await container.get(ILLMQueue)
    logger = await container.get(AISearchLogger)
    async_redis_storage = await container.get(KeyValueStorageProtocol)
    while True:
        try:
            item = await queue.dequeue_blocking(timeout=5)
            if not item:
                await asyncio.sleep(0.1)
                continue

            ticket_id, payload = item
            if (
                not isinstance(payload, dict)
                or "pack_key" not in payload
                or "result_key" not in payload
            ):
                await queue.set_failed(ticket_id, "Invalid payload: missing pack_key or result_key")
                await queue.ack(ticket_id)

                continue
            pack_key = payload["pack_key"]
            raw = await async_redis_storage.get(pack_key)
            pack = json.loads(raw)
            task_type = pack.get("type")

            if task_type == "search":
                try:
                    worker.send_task(
                        "search_task",
                        args=(ticket_id, payload["pack_key"], payload["result_key"]),
                        queue="default",
                        task_id=ticket_id,
                    )
                except Exception as e:
                    await queue.set_failed(ticket_id, f"send_task(search) error: {e!r}")
                    await queue.ack(ticket_id)

            elif task_type == "generate":
                try:
                    worker.send_task(
                        "generate_task",
                        args=(ticket_id, payload["pack_key"], payload["result_key"]),
                        queue="default",
                        task_id=ticket_id,
                    )
                except Exception as e:
                    await queue.set_failed(ticket_id, f"send_task(generate) error: {e!r}")
                    await queue.ack(ticket_id)

            else:

                await queue.set_failed(ticket_id, f"unknown task type: {task_type!r}")
                await queue.ack(ticket_id)
        except Exception as e:
            logger.error(f"{e} - Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² drain queue loop")
            await asyncio.sleep(1)


async def _processing_sweeper(period_sec: int = 10, stale_sec: int = 60) -> None:
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¿Ñ€Ð¾Ñ‚ÑƒÑ…ÑˆÐ¸Ñ… Ñ‚Ð¸ÐºÐµÑ‚Ð¾Ð² Ð¸ Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð² Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸"""
    assert container is not None
    queue = await container.get(ILLMQueue)
    _logger = await container.get(AISearchLogger)
    while True:
        try:
            n = await queue.sweep_processing(stale_sec=stale_sec)
            if n:
                _logger.warning(f"sweep_processing: requeued {n} stale tickets")
        except Exception as e:
            _logger.error(f"sweep_processing error: {e!r}")
        await asyncio.sleep(period_sec)


@worker_process_init.connect
def on_worker_process_init(**kwargs: dict[str, tp.Any]) -> None:
    """ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ð¿ÐµÑ€ÐµÐ´ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ Ð²Ð¾Ñ€ÐºÐµÑ€Ð°"""
    global drain_task, sweep_task # noqa: PLW0603

    asyncio.set_event_loop(loop)
    init_container_and_model()
    # Ð—Ð°Ð¿ÑƒÑÐº drain loop Ð¸ sweep_task Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ðµ
    drain_task = asyncio.ensure_future(_queue_drain_loop(), loop=loop)
    sweep_task = asyncio.ensure_future(_processing_sweeper(), loop=loop)
    # Ð—Ð°Ð¿ÑƒÑÐº loop Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
    def _start_loop() -> None:
        loop.run_forever()

    threading.Thread(target=_start_loop, daemon=True).start()


@task_prerun.connect
def on_task_prerun(task: tp.Callable, task_id: str, **kwargs: dict[str, tp.Any]) -> None:
    """ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ð¿ÐµÑ€ÐµÐ´ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸"""
    task._container = container
    task._model = model
    task.task_id = task_id


@worker_process_shutdown.connect
def on_worker_process_shutdown(**kwargs: dict[str, tp.Any]) -> None:
    """ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ð¿Ð¾ÑÐ»Ðµ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð²Ð¾Ñ€ÐºÐµÑ€Ð°"""

    async def _stop_drain_and_sweep() -> None:
        if drain_task:
            drain_task.cancel()
            with contextlib.suppress(Exception):
                await drain_task
        if sweep_task:  # ðŸ”½ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Â«Ð¿Ð¾Ð´Ð¼ÐµÑ‚Ð°Ð»ÑŒÑ‰Ð¸ÐºÂ»
            sweep_task.cancel()
            with contextlib.suppress(Exception):
                await sweep_task

    async def _run() -> None:
        await _stop_drain_and_sweep()
        if container:
            vllm_client = await container.get(IVLLMAdapter)
            await vllm_client.close()
            await container.close()

    run_coroutine(_run())
