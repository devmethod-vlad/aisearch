import json
import time
import typing as tp

import pandas as pd
from opensearchpy import (
    OpenSearch,
    helpers as os_helpers,
)

from app.common.logger import AISearchLogger
from app.infrastructure.adapters.interfaces import IOpenSearchAdapter
from app.infrastructure.utils.metrics import metrics_print
from app.domain.schemas.open_search import OSIndexSchema
from app.settings.config import Settings


class OpenSearchAdapter(IOpenSearchAdapter):
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è opensearch"""

    def __init__(self, settings: Settings, logger: AISearchLogger):
        os_init_start = time.perf_counter()
        self.config = settings.opensearch
        self.client = OpenSearch(
            hosts=[{"host": self.config.host, "port": self.config.port}],
            http_compress=True,
            http_auth=((self.config.user, self.config.password) if self.config.user else None),
            use_ssl=self.config.use_ssl,
            verify_certs=self.config.verify_certs,
        )
        self.logger = logger
        self.os_schema = self._load_os_schema_from_json(self.config.schema_path)
        metrics_print("üïí –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OPENSEARCH", os_init_start)



    def build_index(self, data: dict[str, tp.Any]) -> None:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞"""
        self.logger.info("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ OS ...")
        self._ensure_os_index(recreate=self.config.recreate_index)
        self._os_optimize_for_bulk(on=True)
        self._os_bulk_index(data=data, chunk_size=self.config.bulk_chunk_size)
        self._os_optimize_for_bulk(on=False)
        self.logger.info("–ò–Ω–¥–µ–∫—Å OS –ø–æ—Å—Ç—Ä–æ–µ–Ω")

    def search(self, body: dict, size: int) -> list[dict]:
        """–ü–æ–∏—Å–∫ –ø—Ä–∏ –ø–æ–º–æ—â–∏ opensearch"""
        resp = self.client.search(index=self.config.index_name, body=body, size=size) # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ self.os_schema.index_name - –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ recreate –±—É–¥–µ—Ç —Å—Ç–æ—è—Ç—å –≤—Å–µ–≥–¥–∞, —á—Ç–æ –Ω–µ –æ—á —Ö–æ—Ä–æ—à–æ
        return resp["hits"]["hits"]

    def _os_optimize_for_bulk(self, on: bool) -> None:
        if on:
            self.client.indices.put_settings(
                index=self.config.index_name,
                body={"index": {"refresh_interval": "-1", "translog.durability": "async"}},
            )
        else:
            self.client.indices.put_settings(
                index=self.config.index_name,
                body={"index": {"refresh_interval": "1s", "translog.durability": "request"}},
            )
            self.client.indices.refresh(index=self.config.index_name)

    def _os_bulk_index(self, data: list[dict[str, tp.Any]], chunk_size: int = 1000) -> None:
        chunk_size = chunk_size or self.os_schema.bulk_chunk_size
        idx_name = self.os_schema.index_name
        id_field = self.os_schema.id_field

        # –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ç–∏–ø–∞–º –∏–∑ –º—ç–ø–ø–∏–Ω–≥–∞
        props = (self.os_schema.mappings.get("properties") or {})
        type_of: dict[str, str] = {k: (v.get("type") or "") for k, v in props.items()}

        def coerce(field: str, value: tp.Any) -> tp.Any:
            t = type_of.get(field, "")
            if value is None:
                return None
            try:
                if t in ("keyword", "text"):
                    return str(value)
                if t in ("integer", "short", "byte", "long"):
                    return int(value)
                if t in ("float", "half_float", "scaled_float", "double"):
                    return float(value)
                if t == "boolean":
                    return bool(value)
                return value
            except Exception:
                return None

        def gen_actions() -> tp.Iterator[dict[str, tp.Any]]:
            for row in data:
                # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç–∏–ø–∞–º–∏
                doc = {field: coerce(field, value) for field, value in row.items() if field in type_of}

                _id = doc.get(id_field)
                yield {
                    "_op_type": "index",
                    "_index": idx_name,
                    **({"_id": _id} if _id is not None else {}),
                    "_source": doc,
                }

        os_helpers.bulk(self.client, gen_actions(), chunk_size=chunk_size, request_timeout=120)

    def upsert(self, data: list[dict[str, tp.Any]]) -> None:
        """Upsert –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ OpenSearch (–æ–±–Ω–æ–≤–ª—è–µ—Ç –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç)"""
        if not data:
            self.logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è upsert –≤ OS")
            return

        self.logger.info(f"üîÑ Upsert {len(data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ OS ...")

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∏–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self._ensure_os_index(recreate=False)

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–¥ bulk-–∑–∞–ø–∏—Å—å—é
        self._os_optimize_for_bulk(on=True)
        self._os_bulk_upsert(data=data, chunk_size=self.config.bulk_chunk_size)
        self._os_optimize_for_bulk(on=False)

        self.logger.info("‚úÖ Upsert OS –∑–∞–≤–µ—Ä—à–µ–Ω")

    def _os_bulk_upsert(self, data: list[dict[str, tp.Any]], chunk_size: int = 1000) -> None:
        idx_name = self.os_schema.index_name
        id_field = self.os_schema.id_field
        props = self.os_schema.mappings.get("properties", {})
        type_of: dict[str, str] = {k: (v.get("type") or "") for k, v in props.items()}

        def coerce(field: str, value: tp.Any) -> tp.Any:
            t = type_of.get(field, "")
            if value is None:
                return None
            try:
                if t in ("keyword", "text"):
                    return str(value)
                if t in ("integer", "short", "byte", "long"):
                    return int(value)
                if t in ("float", "half_float", "scaled_float", "double"):
                    return float(value)
                if t == "boolean":
                    return bool(value)
                return value
            except Exception:
                return None

        def gen_actions():
            for row in data:
                doc = {field: coerce(field, value) for field, value in row.items() if field in type_of}
                _id = doc.get(id_field)
                if _id is None:
                    continue
                yield {
                    "_op_type": "update",
                    "_index": idx_name,
                    "_id": _id,
                    "doc": doc,
                    "doc_as_upsert": True,
                }

        os_helpers.bulk(self.client, gen_actions(), chunk_size=chunk_size, request_timeout=120)

    def _ensure_os_index(self, recreate: bool = False) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å —Ä—É—Å—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º.
        OS_INDEX_ANSWER=true|false ‚Äî –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ª–∏ –ø–æ–ª–µ answer –∫–∞–∫ text (–∏–Ω–∞—á–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –≤ _source).
        """
        idx_name = self.os_schema.index_name

        if recreate and self.client.indices.exists(index=idx_name, expand_wildcards="all"):
            self.client.indices.delete(index=idx_name, ignore=[400, 404])

        if not self.client.indices.exists(index=idx_name):
            body = {
                "settings": self.os_schema.settings,
                "mappings": self.os_schema.mappings,
            }
            self.client.indices.create(index=idx_name, body=body)

    def _load_os_schema_from_json(self, path: str) -> OSIndexSchema:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        return OSIndexSchema(
            index_name=data.get("index_name", self.config.index_name),
            id_field=data.get("id_field", "row_idx"),
            settings=data.get("settings", {}),
            mappings=data.get("mappings", {}),
            bulk_chunk_size=(data.get("bulk") or {}).get("chunk_size", self.config.bulk_chunk_size),
        )

    def fetch_existing(self, size: int = 10000) -> list[dict[str, tp.Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ OpenSearch"""
        idx_name = self.os_schema.index_name
        self.logger.info(f"üì• –ß—Ç–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ {idx_name} ...")
        try:
            query = {"query": {"match_all": {}}}
            resp = self.client.search(index=idx_name, body=query, size=size)
            hits = resp.get("hits", {}).get("hits", [])
            docs = [
                {
                    "ext_id": h["_id"],
                    **h["_source"],
                }
                for h in hits
            ]
            self.logger.info(f"üìÑ –ü–æ–ª—É—á–µ–Ω–æ {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ OS")
            return docs
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ OS –∏–Ω–¥–µ–∫—Å–∞ {idx_name}: {e}")
            return []

    def delete(self, ext_ids: list[str]) -> None:
        """
        –£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ OpenSearch –ø–æ –ø–æ–ª—é ext_id.
        """
        idx_name = self.os_schema.index_name

        if not ext_ids:
            raise ValueError("–ù—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å ext_ids –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")

        self.logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {idx_name} –ø–æ ext_id ...")

        try:
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ –≤—Ä–µ–º—è bulk-–æ–ø–µ—Ä–∞—Ü–∏–π
            self._os_optimize_for_bulk(on=True)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å delete_by_query
            query = {
                "terms": {
                    "ext_id": ext_ids
                }
            }

            resp = self.client.delete_by_query(
                index=idx_name,
                body={"query": query},
                refresh=True,
                conflicts="proceed",  # –Ω–µ –ø–∞–¥–∞–µ—Ç –Ω–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
                request_timeout=300,
            )
            deleted_count = resp.get("deleted", 0)
            self.logger.info(f"üóë –£–¥–∞–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ ext_id: {deleted_count}")

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∏–∑ OS –ø–æ ext_id: {e}")

        finally:
            self._os_optimize_for_bulk(on=False)