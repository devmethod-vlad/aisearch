services:
  aisearch-app:
    container_name: aisearch-app
    env_file:
      - .env
    environment:
      - RERANKER_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/cross-encoder-russian-msmarco
      - MILVUS_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/USER-bge-m3
      - LLM_GLOBAL_SEM_REDIS_DSN=redis://${REDIS_HOSTNAME}:${REDIS_PORT}/${REDIS_DATABASE}
      - NLTK_DATA=${NLTK_DATA_CONTR_PATH}
    volumes:
      - ./:/backend
      - ${APP_MODELSTORE_HOST_PATH}/:${APP_MODELSTORE_CONTR_PATH}/
      - ${GUNICORN_LOGS_HOST_PATH}/:${GUNICORN_LOGS_CONTR_PATH}/
      - ${BM25_INDEX_PATH_HOST}/:${BM25_INDEX_PATH}/
      - ${APP_LOGS_HOST_PATH}/:${APP_LOGS_CONTR_PATH}/
      - ${NLTK_DATA_HOST_PATH}/:${NLTK_DATA_CONTR_PATH}/
    ports:
      - ${APP_PORT}:${APP_PORT}
    healthcheck:
      test: curl -f ${APP_HOST}:${APP_PORT}/healthcheck || exit 1
      interval: 30s
      timeout: 5s
      retries: 3

    depends_on:
      aisearch-milvus:
        condition: service_healthy
        restart: true
      aisearch-celery-worker:
        condition: service_healthy
        restart: true
    command: >
      sh -c "
        exec gunicorn app.main:app -b ${APP_HOST}:${APP_PORT} -w ${APP_WORKERS_NUM} -k uvicorn_worker.UvicornWorker --access-logfile ${GUNICORN_LOGS_CONTR_PATH}/access.log --error-logfile ${GUNICORN_LOGS_CONTR_PATH}/error.log
      "

  aisearch-celery-worker:
    container_name: aisearch-celery-worker
    command: >
      sh -c "
        celery -A app.infrastructure.worker.worker:worker worker --loglevel=info --concurrency ${CELERY_WORKERS_NUM}
      "
    volumes:
      - ./:/backend
      - ${APP_MODELSTORE_HOST_PATH}/:${APP_MODELSTORE_CONTR_PATH}/
      - ${BM25_INDEX_PATH_HOST}/:${BM25_INDEX_PATH}/
      - ${CELERY_LOGS_HOST_PATH}/:${CELERY_LOGS_CONTR_PATH}/
      - ${NLTK_DATA_HOST_PATH}/:${NLTK_DATA_CONTR_PATH}/
    env_file:
      - .env
    environment:
      - RERANKER_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/cross-encoder-russian-msmarco
      - MILVUS_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/USER-bge-m3
      - LLM_GLOBAL_SEM_REDIS_DSN=redis://${REDIS_HOSTNAME}:${REDIS_PORT}/${REDIS_DATABASE}
      - NLTK_DATA=${NLTK_DATA_CONTR_PATH}

    healthcheck:
      test: [ "CMD-SHELL", "celery -A app.infrastructure.worker.worker:worker inspect ping -d \"celery@$(hostname)\" --timeout=5 | grep -q pong" ]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 30s

  aisearch-etcd:
    container_name: aisearch-etcd
    image: quay.io/coreos/etcd:v3.5.18
    env_file:
      - .env
    volumes:
      - ${ETCD_VOLUME_HOST_PATH}:${ETCD_VOLUME_CONTR_PATH}
    command: etcd -advertise-client-urls=http://aisearch-etcd:${ETCD_PORT} -listen-client-urls http://0.0.0.0:${ETCD_PORT} --data-dir /etcd
    healthcheck:
      test: curl -f ${ETCD_HOST}:${ETCD_PORT}/health || exit 1
      interval: 30s
      timeout: 20s
      retries: 3

  aisearch-minio:
    container_name: aisearch-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    env_file:
      - .env
    ports:
      - ${MINIO_WEB_UI_PORT}:${MINIO_WEB_UI_PORT}
      - ${MINIO_PORT}:${MINIO_PORT}
    volumes:
      - ${MINIO_VOLUME_HOST_PATH}:${MINIO_VOLUME_CONTR_PATH}
    command: minio server /minio_data --console-address :${MINIO_WEB_UI_PORT}
    healthcheck:
      test: curl -f ${MINIO_HOST}:${MINIO_PORT}/minio/health/live || exit 1
      interval: 30s
      timeout: 20s
      retries: 3

  aisearch-milvus:
    container_name: aisearch-milvus
    image: milvusdb/milvus:v2.5.12
    env_file:
      - .env
    command: [ "milvus", "run", "standalone" ]
    security_opt:
      - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: aisearch-etcd:${ETCD_PORT}
      MINIO_ADDRESS: aisearch-minio:${MINIO_PORT}
    volumes:
      - ${MILVUS_VOLUME_HOST_PATH}:${MILVUS_VOLUME_CONTR_PATH}
    healthcheck:
      test: curl -f ${MILVUS_HOST}:${MILVUS_WEB_UI_PORT}/healthz || exit 1
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - ${MILVUS_PORT}:${MILVUS_PORT}
      - ${MILVUS_WEB_UI_PORT}:${MILVUS_WEB_UI_PORT}
    depends_on:
      - aisearch-etcd
      - aisearch-minio

  attu:
    image: zilliz/attu:v2.5.0
    container_name: aisearch-attu
    ports:
      - 8010:3000
    depends_on:
      - aisearch-milvus

  aisearch-opensearch:
    image: opensearchproject/opensearch:2.12.0
    container_name: aisearch-opensearch
    env_file:
      - .env
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9200" ]
      interval: 10s
      timeout: 5s
      retries: 30

#  aisearch-vllm:
#    image: vllm/vllm-openai:latest
#    container_name: aisearch-vllm
#    ports:
#      - 8000:8000
#    volumes:
#      - ${APP_MODELSTORE_HOST_PATH}/:${APP_MODELSTORE_CONTR_PATH}/
#    env_file:
#      - .env
#    environment:
#      - NVIDIA_VISIBLE_DEVICES=all
#      - HF_HUB_OFFLINE=1
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - capabilities: [ gpu ]
#              driver: nvidia
#              count: all
#    shm_size: 16g
#    command: >
#      --model ${APP_MODELSTORE_CONTR_PATH}/${VLLM_MODEL_NAME}
#      --quantization awq
#      --served-model-name ${VLLM_MODEL_SERVED_NAME}
#      --max-model-len ${VLLM_MAX_INPUT_TOKENS}
#      --gpu-memory-utilization ${VLLM_GPU_MEMORY_UTILIZATION}
#      --trust-remote-code
#      --port ${VLLM_PORT}
