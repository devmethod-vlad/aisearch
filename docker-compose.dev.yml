services:
  aisearch-app:
    build:
      context: .
      dockerfile: Dockerfile_api
      args:
        https_proxy: ${HTTPS_PROXY}
        http_proxy: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        HTTP_PROXY: ${HTTP_PROXY}
    healthcheck:
      disable: true
    command: >
      sh -c "
        exec uvicorn app.main:app --host ${APP_HOST} --port ${APP_PORT} --reload
      "

  aisearch-celery-worker:
    build:
      context: .
      dockerfile: Dockerfile_search_main
      args:
        https_proxy: ${HTTPS_PROXY}
        http_proxy: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        HTTP_PROXY: ${HTTP_PROXY}
        IMAGE_NAME_BASE: ${IMAGE_NAME_BASE}
        IMAGE_NAME: ${IMAGE_NAME}
        IMAGE_NAME_DEPS: ${IMAGE_NAME_DEPS}
        REGISTRY: ${REGISTRY}
        CUDA_IMAGE: ${CUDA_IMAGE}
        CUDA_WHEEL: ${CUDA_WHEEL}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  aisearch-updater:
    build:
      context: .
      dockerfile: Dockerfile_search_main
      args:
        https_proxy: ${HTTPS_PROXY}
        http_proxy: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        HTTP_PROXY: ${HTTP_PROXY}
        IMAGE_NAME_BASE: ${IMAGE_NAME_BASE}
        IMAGE_NAME: ${IMAGE_NAME}
        IMAGE_NAME_DEPS: ${IMAGE_NAME_DEPS}
        REGISTRY: ${REGISTRY}
        CUDA_IMAGE: ${CUDA_IMAGE}
        CUDA_WHEEL: ${CUDA_WHEEL}
    command:
      ["python3", "-m", "app.scheduler"]
    volumes:
      - ./:/backend
      - ${APP_MODELSTORE_HOST_PATH}/:${APP_MODELSTORE_CONTR_PATH}/
      - ${BM25_INDEX_PATH_HOST}/:${BM25_INDEX_PATH}/
      - ${EXTRACT_LOGS_HOST_PATH}/:${EXTRACT_LOGS_CONTR_PATH}/
      - ${NLTK_DATA_HOST_PATH}/:${NLTK_DATA_CONTR_PATH}/
    env_file:
      - .env
    environment:
      - RERANKER_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/${RERANKER_MODEL_NAME}
      - MILVUS_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/${MILVUS_MODEL_NAME}
      - LLM_GLOBAL_SEM_REDIS_DSN=redis://${REDIS_HOSTNAME}:${REDIS_PORT}/${REDIS_DATABASE}
      - NLTK_DATA=${NLTK_DATA_CONTR_PATH}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  aisearch-redis:
    container_name: aisearch-redis
    image: redis:7.4.2
    env_file:
      - .env
    hostname: ${REDIS_HOSTNAME}
    command: --port ${REDIS_PORT}
    ports:
      - ${REDIS_PORT}:${REDIS_PORT}

  aisearch-redisinsight:
    container_name: aisearch-redisinsight
    image: redis/redisinsight:latest
    env_file:
      - .env
    ports:
      - ${REDISINSIGHT_PORT}:5540

  aisearch-queue-worker:
    container_name: aisearch-queue-worker
    build:
      context: .
      dockerfile: Dockerfile_queue
      args:
        https_proxy: ${HTTPS_PROXY}
        http_proxy: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        HTTP_PROXY: ${HTTP_PROXY}
    command: >
        sh -c "python3 -m app.infrastructure.queue_worker.worker --loglevel=info -Q gpu-search"
    volumes:
      - ./:/backend
      - ${CELERY_LOGS_QUEUE_HOST_PATH}/:${CELERY_LOGS_QUEUE_CONTR_PATH}/
    env_file:
      - .env
    environment:
      - RERANKER_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/cross-encoder-russian-msmarco
      - MILVUS_MODEL_NAME=${APP_MODELSTORE_CONTR_PATH}/USER-bge-m3
      - LLM_GLOBAL_SEM_REDIS_DSN=redis://${REDIS_HOSTNAME}:${REDIS_PORT}/${REDIS_DATABASE}
      - NLTK_DATA=${NLTK_DATA_CONTR_PATH}

  aisearch-os-dashboards:
    image: opensearchproject/opensearch-dashboards:2.12.0
    container_name: aisearch-os-dashboards
    environment:
      OPENSEARCH_HOSTS: '["http://aisearch-opensearch:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: true
    ports:
      - "5601:5601"
    depends_on:
      aisearch-opensearch:
        condition: service_healthy

  attu:
    image: zilliz/attu:v2.5.0
    container_name: aisearch-attu
    ports:
      - 8010:3000
    depends_on:
      aisearch-milvus:
        condition: service_healthy